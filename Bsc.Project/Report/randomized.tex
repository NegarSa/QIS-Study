\chapter{پیچیدگی ارتباطی تصادفی}\label{chapter_rand}

استفاده از تصادف در بسیاری از حوزه‌های الگوریتمی، کاربرد زیادی دارد و پیچیدگی ارتباطی نیز از این امر مستثنا نیست. در این قسمت، سه مدل پیچیدگی تصادفی را بررسی خواهیم کرد و علاوه بر ارتباط آن‌ها، چند تکنیک به‌دست آوردن کمینه را نیز در نظر خواهیم گرفت. 
 \cite{nissan09,
 		lee09,
 		tim15,
 		toni14,
 		sherstov18}
 

\section{مدل سکه خصوصی}
این مدل بر فرض این که هر یک از بازیکنان به مقدار نامحدودی از بیت‌های رندوم دسترسی دارند. این مدل نیز مانند مدل قطعی، با یک درخت پروتکل قابل نمایش است.\\
تعریف درخت پروتکل برای مدل سکه خصوصی\footnote{Private Coin} به شکل زیر خواهد بود. در هر راس درخت ($v$)، توابع مشخص‌کننده مسیر $A_v , B_v$ توابع تصادفی هستند. به بیان دیگر، $A_v : X \rightarrow [0,1] $ احتمال انتخاب فرزند سمت راست را مشخص می‌کند. برای تعریف دقیق محاسبه یک تابع $f$، بیت‌های رندوم آلیس و باب را به ترتیب با $r_A, r_B$ نمایش می‌دهیم. \\
\begin{definition}
می‌گوییم پروتکل تصادفی $\Pi$ تابع $f : X \times Y \rightarrow Z$ را با خطای $\epsilon$ محاسبه می‌کند اگر:
\begin{equation}
\Pr_{r_A, r_B} [\Pi(x, y; r_A, r_B) = f(x,y)] \geq 1 - \epsilon \quad \forall x \in X, y \in Y.
\end{equation}
\end{definition}
هزینه پروتکل تصادفی مثل حالت قطعی، برابر تعداد بیت‌های مبادله‌شده (عمق درخت پروتکل) خواهد بود. حداقل هزینه پروتکلی که $ّf$ را با خطای $\epsilon$ محاسبه می‌کند را با $R_\epsilon(f)$ نمایش می‌دهیم. به علاوه، در مسائل مربوط به پیچیدگی محاسباتی $\epsilon = \frac{1}{3}$ در نظر گرفته می‌شود و داریم $R(f) = R_{\frac{1}{3}}(f)$.\\
در تمام پروتکل‌های تصادفی، می‌توان با تکرار پروتکل و انتخاب پر تکرارترین پاسخ، احتمال جواب درست را افزایش داد. در نتیجه:
\begin{equation}
R_{\epsilon}(f) = O(\log \frac{1}{\epsilon}) . R(f)
\end{equation}

\section{مدل سکه عمومی}
این مدل، فرض می‌کند بیت‌های عمومی نامحدود در اختیار آلیس و باب، مشترک هستند. این بیت‌های مشترک را با $r$ نمایش‌داده و داریم:
\begin{definition}
می‌گوییم پروتکل تصادفی $\Pi$ تابع $f : X \times Y \rightarrow Z$ را با خطای $\epsilon$ و سکه‌های عمومی\footnote{Public Coin} محاسبه می‌کند اگر:
\begin{equation}
\Pr_{r} [\Pi(x, y; r) = f(x,y)] \geq 1 - \epsilon \quad \forall x \in X, y \in Y.
\end{equation}
\end{definition}
هزینه حداقل پروتکلی که تابع $f$ را با سکه عمومی محاسبه می‌کند را با $R_\epsilon^{pub} (f)$ نمایش می‌دهیم. به شکل مشابه، از تکرار برای افزایش دقت این مدل نیز می‌توان استفاده کرد.
\begin{example}
حال از مدل‌های بررسی‌شده، برای طراحی پروتکل‌هایی برای تابع تساوی استفاده می‌کنیم. 
\begin{itemize}
\item مدل سکه خصوصی: 
\begin{enumerate}
\item آلیس یک عدد اول به صورت تصادفی از مجموعه $\{2, \dots, 2n\}$ انتخاب می‌کند.
\item آلیس عدد اول انتخاب شده ($p$) و مقدار $x \mod p$ را به باب ارسال می‌کند.
\item باب چک می‌کند که آیا $y \mod p$ برابر با عدد دریافتی هست یا خیر. اگر برابر بود 1 و اگر برابر نبود صفر برمی‌گرداند.
\end{enumerate}
مشخص است که اگر دو عدد با هم برابر باشند، نتیجه این پروتکل همواره درست خواهد بود. ولی اگر $x \neq y$ باشد، ممکن است اعداد اولی وجود داشته باشند به صورتی که $x \mod p = y \mod p$. پس در این حالت، خطا وجود خواهد داشت. حال تلاش می‌کنیم مقدار خطا را محاسبه کنیم.\\
فرض کنید که مجموعه $\{p_1, p_2, \dots, p_k\}$ مجموعه تمام اعداد اولی باشد که $x \mod p_i = y \mod p_i$. در نتیجه:
\begin{equation*}
x \mod P = y \mod P \quad P = p_1p_2\dots p_k
\end{equation*}
حال از آنجایی که $p_i \geq 2$ است، $P \geq 2^k$ خواهد بود. ولی $P$ نمی‌تواند بیش‌تر از $2^n$ باشد، چون $x \neq y$ است. پس $2^k \leq 2^n$ است و $k \leq n$ خواهد بود. حال از آنجایی که عدد اول از مجموعه‌ای به اندازه $2n$ انتخاب شده است، احتمال این که یکی از این اعداد اول به تصادف انتخاب شود کمتر از $\frac{1}{2}$ خواهد بود. (و این احتمال با تکرار می‌تواند کمتر شود.)\\
هزینه این پروتکل $O(\log n)$ است. توجه کنید که حداقل مقدار مخابره برای حالت قطعی، $O(n)$ است.
\item مدل سکه عمومی: ($r = r_1\dots r_m$ بیت‌های تصادفی مشترک‌ هستند.)
\begin{enumerate}
\item آلیس مقدار زیر را محاسبه کرده و برای باب را ارسال می‌کند:
\[\sum^n_{i=1} x_ir_i\ \mod 2\]
\item باب مقدار زیر را محاسبه کرده، با مقدار فرستاده شده توسط آلیس مقایسه می‌کند. اگر برابر بودند 1 و در غیر این صورت صفر خروجی می‌دهد.
\[\sum^n_{i=1} y_ir_i\ \mod 2\]
\end{enumerate}
همچنان مشخص است که اگر این دو ورودی با هم برابر باشند، جواب حتما درست است. ولی اگر تساوی برقرار نباشد، به احتمال $1/2$ ممکن است جواب اشتباه تشخیص داده شود و مثل حالت قبل، می‌توان با تکرار احتمال خطا را کم کرد. نکته دیگر، این است که در این مدل، فقط با فرستادن یک بیت اطلاعات نتیجه مشخص می‌شود و پیچیدگی برابر با $O(1)$ خواهد بود.
\end{itemize}
\end{example}
همان‌طور که از مثال بالا مشخص است، مدل سکه عمومی از سکه خصوصی قوی‌تر است، یعنی با مدل عمومی می‌توان بدون هزینه اضافی مدل خصوصی را شبیه‌سازی کرد، ولی نه برعکس. در نتیجه:
\[R_\epsilon^{pub} (f) \leq R_\epsilon (f)\] 
شبیه‌سازی مدل عمومی با مدل خصوصی نیز ممکن است، ولی با مقداری هزینه همراه خواهد بود. لم نیومن\footnote{Newman's lemma} نتیجه این شبیه‌سازی را بیان می‌کند.
\begin{theorem}
اگر $f : \{0,1\}^n \times \{0,1\}^n \rightarrow Z$ باشد، برای هر مقدار $\epsilon,  \delta \geq 0$ داریم:
\begin{equation}
‌R_{\epsilon+\delta}(f) \leq R_\epsilon^{pub} (f) + O(\log n + \log \frac{1}{\delta}
)
\end{equation}
\end{theorem}
\section{مدل توزیعی}\label{dist_rand}
تا به حال در تمام مدل‌های بررسی شده، عنصر تصادف در عملکرد پروتکل بوده است. در مدل توزیعی\footnote{Distributional} ورودی را تصادفی فرض می‌کنند. 
\begin{definition}
فرض کنید $\mu$ یک توزیع روی $X \times Y$ است. 
می‌گوییم پروتکل تصادفی توزیعی $\Pi$ تابع $f : X \times Y \rightarrow Z$ را با خطای $\epsilon$ و تحت $\mu$ محاسبه می‌کند اگر:
\begin{equation}
\Pr_{(x, y) \thicksim \mu} [\Pi(x, y) = f(x,y)] \geq 1 - \epsilon \quad \forall x \in X, y \in Y.
\end{equation}
\end{definition}

تکنیک‌های کمینه مدل‌های تصادفی که در بخش بعد بررسی خواهند شد، یک توزیع «دشوار» روی ورودی‌ها پیدا می‌کنند و نشان می‌دهند که هیچ پروتکل قطعی‌ و بهینه‌ای نمی‌تواند تابع مورد نظر را تحت این توزیع محاسبه کند. این تکنیک بر قضیه زیر که توسط Yao اثبات شده است مبتنی‌ست:
\begin{theorem}
اگر $f : X \times Y \rightarrow Z$ و $\epsilon \geq 0$ باشد، داریم:
\begin{equation}
\max_\mu D^\mu_{\epsilon} = R_\epsilon^{pub}(f)
\end{equation}
\end{theorem}
\section{کمینه‌یابی}
\subsection{ناهمگنی}
همانطور که در قسمت قبل بیان شد، استفاده از یک توزیع سخت، و نشان دادن کمینه‌ای برای پروتکل قطعی‌ای که ورودی را تحت آن توزیع محاسبه می‌کند، با کمینه محاسبه همان تابع توسط یک پروتکل تصادفی سکه عمومی برابر است. برای استفاده از این نکته، مفهوم جدیدی را تعریف می‌کنیم:
\begin{definition}
اگر  $f : X \times Y \rightarrow Z$ و $\mu$ یک توزیع روی $X \times Y$ باشد، می‌توان برای هر مستطیل R ناهمگنی
\footnote{Discrepancy}
را به صورت زیر تعریف کرد:
\begin{equation}
disc_\mu (f,R) = |\mu (R \cap f^{-1}(0) - \mu (R \cap f^{-1}(1)|
\end{equation}
و
\begin{equation}
disc_\mu (f) = \max_R \ disc_\mu (f,R).
\end{equation}
\end{definition}
به صورت غیررسمی، معیار ناهمنگی پایین یعنی مستطیل‌های بزرگ تعداد تقریبا برابری صفر و یک دارند. \\
این معیار را به یک شکل مشابه نیز می‌توان تعریف کرد.
در نظر بگیرید که S یک ماتریس $|X| \times |Y|$ است و هر درایه آن به شکل زیر محاسبه می‌شود:
\begin{equation*}
S_{x, y} = \mu(x,y)(-1)^{f(x,y)}.
\end{equation*}
و برای محاسبه معیار ناهمنگی:
\begin{equation}
disc_\mu (f,R) = \Bigg|\sum_{(x,y) \in R} S_{x,y}\ \Bigg|
\end{equation}

\subsection{محدودکردن مقیاس ناهمگنی و کمینه‌یابی}
\begin{theorem}
اگر برای یک تابع باینری $f$، توزیع $\mu$ وجود داشته باشد به صورتی که $disc_\mu (f) \leq 2^{-c}$ باشد، $R^{pub}_\epsilon = \Omega(c)$ خواهد بود.
\end{theorem}
با توجه به قضیه بالا، نیاز است که تکنیکی برای محدود کردن مقدار ناهمنگی بیابیم و از آن برای به‌دست آوردن کمینه‌هایی روی پیچیدگی تصادفی عمومی به‌دست آوریم. معروف ترین این تکنیک‌ها‌، تکنیک مقدار ویژه\footnote{eigenvalue} است.

\begin{lemma}
برای هر ماتریس متقارن $M$، ناهمگنی مستطیل $A \times B$ حداکثر برابر با $\lambda_{max} (M) \sqrt{|R|}$ است، که در آن $\lambda_{max}$ بزرگ‌ترین مقدار ویژه تابع است. به بیان دیگر:
\begin{equation}
disc_\mu(f, R) \leq \lambda_{max} (M) \sqrt{|A||B|}
\end{equation}
\end{lemma}
و از این تکنیک می‌توان برای به‌‌دست آوردن مقدار ناهمگنی برای بعضی از مسائل که ماتریس متقارن دارند استفاده کرد.